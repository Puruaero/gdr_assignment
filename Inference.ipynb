{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "The model with least val_loss during training is saved and used for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Lambda Function\n",
    "def get_last_elements(tensor) : \n",
    "    last_words = []\n",
    "    for i in range(tensor.shape[0]) : \n",
    "        last_word_representation = tensor[i][-1]\n",
    "        expanded = expand_dims(last_word_representation, axis=0)\n",
    "        expanded = tensorflow.reshape(expanded, (30, 1))\n",
    "        last_words.append(expanded)\n",
    "    return tensorflow.convert_to_tensor(last_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 \n",
    "# for word_vec_size to change word2vec has to be trained for it\n",
    "word_vec_size = 100\n",
    "\n",
    "inp = Input(batch_shape=(batch_size, None, word_vec_size))\n",
    "encoded1 = LSTM(30, return_sequences=True, activation='tanh')(inp)\n",
    "encoded = Lambda(lambda x: get_last_elements(x))(encoded1)\n",
    "convolved = Conv1D(32, 2, input_shape=(1, 30), activation='relu')(encoded)\n",
    "pooled = MaxPooling1D(3, strides=3)(convolved)\n",
    "flattened = Flatten()(pooled)\n",
    "output_probabilities = Dense(8, activation='sigmoid')(flattened)\n",
    "output_vector = Lambda(lambda x: x*8)(output_probabilities)\n",
    "model = Model(inp, output_vector)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(), 'glassdoor_problem/model.h5')\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_model = Word2Vec.load(os.path.join(os.getcwd(), 'glassdoor_problem/wordvecmodel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'glassdoor_problem/label_map.pkl'), 'rb') as f: \n",
    "    label_map = pickle.load(f)\n",
    "\n",
    "reverse_label_map = {}\n",
    "for label in label_map : \n",
    "    reverse_label_map[label_map[label]] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be used for making inference\n",
    "def get_matrix_for_prediction(text) : \n",
    "    words = text.split(\" \")\n",
    "    words_array = [words]\n",
    "    inp = get_word2vec_input_matrix(words_array, wordvec_model)\n",
    "    return inp\n",
    "\n",
    "def infer(model, text) : \n",
    "    cleaned_text = clean_text(text)\n",
    "    m = get_matrix_for_prediction(cleaned_text[0])\n",
    "    prediction = model.predict(m)\n",
    "    all_prediction = prediction[0]\n",
    "    labels_predicted_index = [i for i in range(len(all_prediction)) if all_prediction[i]>=4]\n",
    "    labels = [reverse_label_map[index] for index in labels_predicted_index]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salary_benefits': 0,\n",
       " 'wlb_working_conditions': 1,\n",
       " 'tech_product': 2,\n",
       " 'culture_team': 3,\n",
       " 'Job Security/Advancement': 4,\n",
       " 'haras_discrim_sexism': 5,\n",
       " 'management': 6,\n",
       " 'business_vision_competitors': 7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wlb_working_conditions']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(model, \"great work life balance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
