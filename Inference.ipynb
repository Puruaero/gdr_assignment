{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "The model with least val_loss during training is saved and used for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Lambda Function\n",
    "def get_last_elements(tensor) : \n",
    "    last_words = []\n",
    "    for i in range(tensor.shape[0]) : \n",
    "        last_word_representation = tensor[i][-1]\n",
    "        expanded = expand_dims(last_word_representation, axis=0)\n",
    "        expanded = tensorflow.reshape(expanded, (30, 1))\n",
    "        last_words.append(expanded)\n",
    "    return tensorflow.convert_to_tensor(last_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 \n",
    "# for word_vec_size to change word2vec has to be trained for it\n",
    "word_vec_size = 100\n",
    "\n",
    "inp = Input(batch_shape=(batch_size, None, word_vec_size))\n",
    "encoded1 = LSTM(30, return_sequences=True, activation='tanh')(inp)\n",
    "encoded = Lambda(lambda x: get_last_elements(x))(encoded1)\n",
    "convolved = Conv1D(32, 2, input_shape=(1, 30), activation='relu')(encoded)\n",
    "pooled = MaxPooling1D(3, strides=3)(convolved)\n",
    "flattened = Flatten()(pooled)\n",
    "output_probabilities = Dense(8, activation='sigmoid')(flattened)\n",
    "output_vector = Lambda(lambda x: x*8)(output_probabilities)\n",
    "model = Model(inp, output_vector)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(), 'glassdoor_problem/model.h5')\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_model = Word2Vec.load(os.path.join(os.getcwd(), 'glassdoor_problem/wordvecmodel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'glassdoor_problem/label_map.pkl'), 'rb') as f: \n",
    "    label_map = pickle.load(f)\n",
    "\n",
    "reverse_label_map = {}\n",
    "for label in label_map : \n",
    "    reverse_label_map[label_map[label]] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be used for making inference\n",
    "def get_matrix_for_prediction(text) : \n",
    "    words = text.split(\" \")\n",
    "    words_array = [words]\n",
    "    inp = get_word2vec_input_matrix(words_array, wordvec_model)\n",
    "    return inp\n",
    "\n",
    "def infer(model, text) : \n",
    "#     cleaned_text = clean_text(text)\n",
    "    cleaned_text = [text]\n",
    "    m = get_matrix_for_prediction(cleaned_text[0])\n",
    "    prediction = model.predict(m)\n",
    "    all_prediction = prediction[0]\n",
    "    labels_predicted_index = [i for i in range(len(all_prediction)) if all_prediction[i]>=4]\n",
    "    labels = [reverse_label_map[index] for index in labels_predicted_index]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salary_benefits': 0,\n",
       " 'wlb_working_conditions': 1,\n",
       " 'tech_product': 2,\n",
       " 'culture_team': 3,\n",
       " 'Job Security/Advancement': 4,\n",
       " 'haras_discrim_sexism': 5,\n",
       " 'management': 6,\n",
       " 'business_vision_competitors': 7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/purushottamsinha/Desktop/glassdoor_problem/test_data.pkl', 'rb') as f: \n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilabel = [sen for sen in test_data if sum(sen[1])==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8086423e-07 2.2034757e-07 4.0903188e-08 7.4818487e-08 3.0470321e-05\n",
      "  4.8173522e-03 6.8821711e-04 7.9810734e+00]]\n",
      "['business_vision_competitors']\n",
      "['business_vision_competitors']\n",
      "\n",
      "\n",
      "[[9.6481040e-07 2.2757991e-05 9.8474584e-06 4.6060830e-02 2.9483456e-07\n",
      "  2.7530132e-07 7.9999981e+00 3.4726869e-05]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[6.6178018e-06 2.6610176e-05 3.3394852e-05 2.9476743e-05 7.9996233e+00\n",
      "  7.9174810e-05 1.4169108e-04 5.1230524e-02]]\n",
      "['Job Security/Advancement']\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[2.5343683e-01 2.2295504e-08 7.9052383e-04 3.9381388e-04 7.7749972e+00\n",
      "  1.4121895e-05 2.8316088e-05 3.5229421e-03]]\n",
      "['Job Security/Advancement']\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[1.2311878e-04 2.5718839e-05 3.1269673e-04 2.0342845e-02 1.0188985e-05\n",
      "  1.5215450e-05 7.9999990e+00 1.9427671e-05]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function _make_execution_function.<locals>.distributed_function at 0x13d639378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[[3.2638827e-01 7.2412186e+00 5.7066223e-11 2.2484292e-09 7.2400463e-03\n",
      "  7.9880778e-07 3.5032021e-12 1.1735444e-01]]\n",
      "['wlb_working_conditions']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[4.0201380e-06 1.7181037e-05 3.7918937e-05 4.9677194e-08 7.9998960e+00\n",
      "  2.5661264e-05 1.5336547e-04 5.1080495e-02]]\n",
      "['Job Security/Advancement']\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[7.9992380e+00 1.4417485e-04 4.8711866e-09 2.8499203e-08 3.8196755e-04\n",
      "  2.3311461e-05 6.1457177e-09 1.3259868e-04]]\n",
      "['salary_benefits']\n",
      "['salary_benefits']\n",
      "\n",
      "\n",
      "[[1.2407437e-03 6.7224631e-05 7.9924283e+00 5.7474910e-05 2.1751992e-01\n",
      "  2.1613962e-03 2.8805462e-01 5.1748292e-03]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[1.2308449e-08 1.3373130e-09 1.9605144e-11 1.4341685e-01 1.5008009e-11\n",
      "  7.9708099e+00 3.3299516e-11 2.6262851e-04]]\n",
      "['haras_discrim_sexism']\n",
      "['haras_discrim_sexism']\n",
      "\n",
      "\n",
      "[[5.9193011e-05 2.4911928e-06 2.1157501e-07 1.5080612e-06 7.9970112e+00\n",
      "  1.0520631e-05 4.5672863e-08 1.2337159e-02]]\n",
      "['Job Security/Advancement']\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[9.4447105e-06 5.6631400e-08 1.1944798e-05 7.6583007e-07 2.2052543e-03\n",
      "  6.6436385e-03 1.0812387e-05 7.9879541e+00]]\n",
      "['business_vision_competitors']\n",
      "['business_vision_competitors']\n",
      "\n",
      "\n",
      "[[1.9433205e-04 4.0747009e-06 6.5131389e-05 4.8214742e-06 7.9863553e+00\n",
      "  6.8295109e-03 2.3096219e-04 2.7754936e+00]]\n",
      "['Job Security/Advancement']\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[4.2792996e-07 5.3799031e-05 9.6817867e-06 1.7719384e-04 3.9480531e-01\n",
      "  5.7306405e-02 4.9344129e-05 7.8672814e+00]]\n",
      "['business_vision_competitors']\n",
      "['business_vision_competitors']\n",
      "\n",
      "\n",
      "[[3.4889491e-10 7.3286414e-02 7.9821291e+00 2.7382784e-03 1.6046882e-03\n",
      "  9.0127905e-06 9.5679118e-09 3.4633176e-03]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[5.7412853e+00 7.9016680e-01 5.7432925e-10 1.8465225e-06 1.1449866e-09\n",
      "  9.6444071e-09 4.5686623e-12 1.4135970e-03]]\n",
      "['salary_benefits']\n",
      "['salary_benefits']\n",
      "\n",
      "\n",
      "[[1.6522057e-09 6.2967991e-03 7.8161631e+00 5.4056988e+00 6.7877081e-05\n",
      "  2.4860090e-09 6.5624589e-11 9.5441444e-03]]\n",
      "['tech_product', 'culture_team']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[1.4829969e-06 3.5224335e-07 1.1400546e-05 1.5450017e-07 9.9224807e-04\n",
      "  3.1764715e-04 6.3507455e-06 7.9949450e+00]]\n",
      "['business_vision_competitors']\n",
      "['business_vision_competitors']\n",
      "\n",
      "\n",
      "[[1.6178317e-06 7.9997931e+00 9.1275208e-05 4.8843255e-08 2.5136544e-06\n",
      "  3.0022083e-04 1.7509892e-08 8.9577428e-05]]\n",
      "['wlb_working_conditions']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[8.8951230e-05 1.8849481e-04 1.5754630e-03 1.8886846e-01 1.7322435e-03\n",
      "  1.7564302e-05 7.9999971e+00 2.5165016e-06]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[5.4824153e-12 4.8815789e-05 4.0458599e-05 1.2525319e-03 3.9206498e-06\n",
      "  7.9971933e+00 1.5234635e-03 2.5176101e-07]]\n",
      "['haras_discrim_sexism']\n",
      "['haras_discrim_sexism']\n",
      "\n",
      "\n",
      "[[6.5825784e-06 7.9988928e+00 2.1209734e-08 8.1934966e-11 1.1999841e-06\n",
      "  2.7778897e-05 3.5549931e-11 3.0631889e-02]]\n",
      "['wlb_working_conditions']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[1.2535907e-07 9.9361580e-07 9.1469936e-11 7.9937992e+00 3.1105894e-06\n",
      "  9.9421866e-09 3.5884614e-08 4.4442939e-05]]\n",
      "['culture_team']\n",
      "['culture_team']\n",
      "\n",
      "\n",
      "[[2.2859220e-11 4.0113274e-08 4.4003013e-06 4.9719724e-06 4.5913646e-09\n",
      "  7.9999914e+00 2.4210827e-03 4.2584990e-05]]\n",
      "['haras_discrim_sexism']\n",
      "['haras_discrim_sexism']\n",
      "\n",
      "\n",
      "[[5.8446454e-05 5.7330111e-04 3.9800329e-05 1.4625256e-02 6.5207838e-05\n",
      "  1.1998216e-06 7.9999990e+00 1.3528285e-06]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[8.7786941e-07 7.9999609e+00 1.7166380e-05 3.3079126e-09 3.0386052e-06\n",
      "  1.9221265e-05 4.0421235e-09 1.6244502e-04]]\n",
      "['wlb_working_conditions']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[1.5962018e+00 3.2549704e-04 4.1405587e-03 2.5435054e-04 1.6826591e-06\n",
      "  2.4219186e-03 7.9949002e+00 1.3445665e-02]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[1.7932648e-06 6.2301398e-05 6.1455573e-08 7.7378445e+00 1.0718488e-05\n",
      "  2.2349914e-06 4.8899301e-07 1.4046212e-01]]\n",
      "['culture_team']\n",
      "['culture_team']\n",
      "\n",
      "\n",
      "[[1.1137553e-03 6.9795597e-08 1.1522070e-01 7.9806585e+00 6.6742353e+00\n",
      "  1.3445871e-03 9.7795762e-03 4.0970543e-05]]\n",
      "['culture_team', 'Job Security/Advancement']\n",
      "['culture_team']\n",
      "\n",
      "\n",
      "[[4.2732541e-08 2.2771956e-06 7.7095045e-08 7.9994307e+00 6.3447587e-02\n",
      "  7.7080058e-06 2.1230806e-04 1.1550970e-05]]\n",
      "['culture_team']\n",
      "['culture_team']\n",
      "\n",
      "\n",
      "[[2.7716247e-09 3.9963806e-09 5.0561925e-06 7.0116897e-08 2.5032339e-06\n",
      "  7.9999914e+00 4.4592798e-06 2.5621126e-03]]\n",
      "['haras_discrim_sexism']\n",
      "['haras_discrim_sexism']\n",
      "\n",
      "\n",
      "[[1.5465369e-08 8.7636244e-03 7.9873724e+00 2.3026965e-03 2.4557651e-03\n",
      "  2.8500142e-07 5.0458937e-07 6.8618509e-04]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[1.1461326e-07 1.2462187e-05 1.5462634e-05 6.3967229e-05 1.1808637e-09\n",
      "  6.3515574e-05 8.6203208e-03 7.9827919e+00]]\n",
      "['business_vision_competitors']\n",
      "['business_vision_competitors']\n",
      "\n",
      "\n",
      "[[2.3953495e-05 1.5446069e-05 4.2758140e-05 4.1001194e-04 7.9999752e+00\n",
      "  3.3918053e-03 1.7802911e-05 5.9345528e-02]]\n",
      "['Job Security/Advancement']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[4.0035177e-11 2.0103829e-04 7.9928584e+00 1.5820594e-03 2.0842799e-07\n",
      "  1.8578251e-07 4.7675433e-11 2.1875426e-03]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[1.9457816e-06 5.3192900e-05 7.0426750e-01 9.2925702e-04 5.1180112e-01\n",
      "  2.6385939e-07 4.4166843e-13 2.3289066e-02]]\n",
      "[]\n",
      "['Job Security/Advancement']\n",
      "\n",
      "\n",
      "[[3.6971848e-08 3.2301492e-04 7.9995871e+00 8.2278766e-06 5.1473358e-05\n",
      "  4.2157129e-07 4.8754468e-05 4.1954292e-04]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[1.8515535e-06 8.4196012e-07 9.2796718e-06 1.6864851e-05 2.5687961e-09\n",
      "  1.0808317e-07 7.9998693e+00 1.3329394e-01]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[7.4591079e+00 3.0401193e-03 7.4471944e-05 3.9041563e-08 4.4003260e-04\n",
      "  2.7158271e-07 3.1925157e-07 1.4368854e-04]]\n",
      "['salary_benefits']\n",
      "['salary_benefits']\n",
      "\n",
      "\n",
      "[[2.4929721e-04 7.9993563e+00 6.9524478e-03 2.8129264e-06 1.1073660e-06\n",
      "  1.6232347e-06 6.2011658e-09 1.4554165e-04]]\n",
      "['wlb_working_conditions']\n",
      "['wlb_working_conditions']\n",
      "\n",
      "\n",
      "[[2.3040117e-05 1.4958057e-03 5.9275430e-05 1.7070672e-02 1.2806942e-03\n",
      "  3.0643565e-07 8.0000000e+00 7.2138334e-07]]\n",
      "['management']\n",
      "['management']\n",
      "\n",
      "\n",
      "[[8.7588880e-08 4.7848473e-04 7.9975958e+00 2.3392320e-04 1.9677973e-04\n",
      "  1.0086547e-06 4.1338822e-06 3.7241071e-03]]\n",
      "['tech_product']\n",
      "['tech_product']\n",
      "\n",
      "\n",
      "[[6.1764851e-12 5.1670617e-07 7.9555615e-09 3.8376592e-07 7.8005606e-08\n",
      "  7.9996338e+00 3.8504049e-02 4.1329330e-03]]\n",
      "['haras_discrim_sexism']\n",
      "['haras_discrim_sexism']\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'diver' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9df88aa21d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munilabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mactual_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6c3a83159f52>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(model, text)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     cleaned_text = [text]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matrix_for_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6c3a83159f52>\u001b[0m in \u001b[0;36mget_matrix_for_prediction\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word2vec_input_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordvec_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/utility.py\u001b[0m in \u001b[0;36mget_word2vec_input_matrix\u001b[0;34m(list_of_words, wordvec_model)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mstore_all_together\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_words\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mstore_all_together\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordvec_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_all_together\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/utility.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mstore_all_together\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_words\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mstore_all_together\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordvec_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_all_together\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/utility.py\u001b[0m in \u001b[0;36mget_word_vector\u001b[0;34m(word, word2vecmodel)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vecmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mword2vecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word2vec_input_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordvec_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'diver' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "for sen in unilabel[0:50] : \n",
    "    prediction = infer(model, sen[0])\n",
    "    actual_labels = [reverse_label_map[i] for i in range(len(sen[1])) if sen[1][i]>1]\n",
    "    print(prediction)\n",
    "    print(actual_labels)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
